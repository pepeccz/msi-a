# =============================================================================
# MSI Automotive - Environment Variables
# =============================================================================

# Project
PROJECT_NAME=MSI Automotive
AGENT_NAME=MSI-a
ENVIRONMENT=development

# =============================================================================
# Database (PostgreSQL)
# =============================================================================
DATABASE_URL=postgresql+asyncpg://msia:msia_password@postgres:5432/msia_db
POSTGRES_DB=msia_db
POSTGRES_USER=msia
POSTGRES_PASSWORD=msia_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# =============================================================================
# Redis
# =============================================================================
REDIS_URL=redis://redis:6379/0
REDIS_PASSWORD=your_redis_password_here
USE_REDIS_STREAMS=true

# =============================================================================
# Chatwoot (WhatsApp Integration)
# =============================================================================
CHATWOOT_API_URL=https://app.chatwoot.com
CHATWOOT_API_TOKEN=your_chatwoot_api_token
CHATWOOT_ACCOUNT_ID=12345
CHATWOOT_INBOX_ID=67890
CHATWOOT_TEAM_GROUP_ID=group_id
CHATWOOT_WEBHOOK_TOKEN=your_webhook_token_min_24_chars
# Domain for Chatwoot active_storage URLs (if different from API domain)
CHATWOOT_STORAGE_DOMAIN=chats.autohomologacion.net

# Next.js Admin Panel (public vars for Chatwoot links)
NEXT_PUBLIC_CHATWOOT_URL=https://app.chatwoot.com
NEXT_PUBLIC_CHATWOOT_ACCOUNT_ID=12345

# =============================================================================
# OpenRouter (LLM API)
# =============================================================================
OPENROUTER_API_KEY=sk-or-your_api_key_here
# DeepSeek is recommended: better reasoning, much cheaper than GPT-4o-mini
# Pricing: $0.14/1M input, $0.28/1M output
LLM_MODEL=deepseek/deepseek-chat
SITE_URL=https://msiautomotive.es
SITE_NAME=MSI Automotive

# =============================================================================
# Admin Panel Authentication
# =============================================================================
ADMIN_USERNAME=admin
# Generate hash with: python -c "from passlib.hash import bcrypt; print(bcrypt.hash('your_password'))"
ADMIN_PASSWORD_HASH=
ADMIN_JWT_SECRET=your_jwt_secret_min_32_chars_here

# =============================================================================
# Application Settings
# =============================================================================
TIMEZONE=Europe/Madrid
LOG_LEVEL=INFO
MESSAGE_BATCH_WINDOW_SECONDS=30

# =============================================================================
# CORS Origins
# =============================================================================
CORS_ORIGINS=http://localhost:3000,http://localhost:8000,http://localhost:8001,http://api:8000

# =============================================================================
# Docker Control (Admin Panel /system page)
# =============================================================================
# On Linux: docker.sock is mounted automatically, leave empty
# On Windows Docker Desktop: enable TCP in Docker Desktop settings, then set:
# DOCKER_HOST=tcp://host.docker.internal:2375
DOCKER_HOST=

# =============================================================================
# RAG System (Normativas)
# =============================================================================
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION_NAME=msi_regulatory_docs
OLLAMA_BASE_URL=http://ollama:11434
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSION=768
BGE_RERANKER_MODEL=BAAI/bge-reranker-large
RAG_TOP_K=20
RAG_RERANK_TOP_K=5
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=200
RAG_CACHE_TTL=3600
DOCUMENT_UPLOAD_DIR=/app/uploads/documents
DOCUMENT_MAX_SIZE_MB=50
RAG_LLM_FALLBACK_MODEL=qwen2.5:3b

# =============================================================================
# Hybrid LLM Architecture
# =============================================================================
# Enable hybrid architecture (local Ollama + cloud OpenRouter)
USE_HYBRID_LLM=true

# Tier 1: Fast local models for simple tasks (classification, extraction)
LOCAL_FAST_MODEL=qwen2.5:3b

# Tier 2: Capable local models for moderate tasks (RAG simple)
LOCAL_CAPABLE_MODEL=llama3:8b

# Vehicle Classification - use local model
USE_LOCAL_VEHICLE_CLASSIFICATION=true
VEHICLE_CLASSIFICATION_MODEL=qwen2.5:3b

# Document Processing - use local model for section mapping
USE_LOCAL_SECTION_MAPPING=true
SECTION_MAPPING_MODEL=qwen2.5:3b

# RAG Query Routing - use local model for simple factual queries
USE_LOCAL_FOR_SIMPLE_RAG=true
RAG_PRIMARY_MODEL=llama3:8b

# LLM Metrics tracking
ENABLE_LLM_METRICS=true
LLM_METRICS_RETENTION_DAYS=90

# =============================================================================
# Token Usage Pricing (EUR per million tokens)
# =============================================================================
# DeepSeek pricing (recommended): $0.14/1M input, $0.28/1M output
# GPT-4o-mini pricing: $0.15/1M input, $0.60/1M output
TOKEN_PRICE_INPUT=0.14
TOKEN_PRICE_OUTPUT=0.28
