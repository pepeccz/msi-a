services:
  # PostgreSQL database
  postgres:
    image: postgres:15-alpine
    container_name: msia-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-msia_db}
      POSTGRES_USER: ${POSTGRES_USER:-msia}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-msia} -d ${POSTGRES_DB:-msia_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Redis cache and pub/sub (with RedisSearch for LangGraph checkpointer)
  redis:
    image: redis/redis-stack:latest
    container_name: msia-redis
    command: redis-stack-server --requirepass ${REDIS_PASSWORD} --save 900 1 --appendonly no
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # API service: FastAPI webhook receiver
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: msia-api
    env_file: .env
    environment:
      # For Windows Docker Desktop: enable TCP in Docker Desktop settings
      # then uncomment the following line:
      # - DOCKER_HOST=tcp://host.docker.internal:2375
      - DOCKER_HOST=${DOCKER_HOST:-}
    ports:
      - "8000:8000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama: Local LLM server
  ollama:
    image: ollama/ollama:latest
    container_name: msia-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Ollama model setup: Downloads required models on startup
  ollama-setup:
    image: ollama/ollama:latest
    container_name: msia-ollama-setup
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - msia-network
    restart: "no"
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Pulling embedding model: nomic-embed-text..."
        ollama pull nomic-embed-text
        echo "Pulling LLM model: gpt-oss:20b..."
        ollama pull gpt-oss:20b
        echo "Pulling LLM model: qwen2.5:3b..."
        ollama pull qwen2.5:3b
        echo "All models downloaded successfully!"
    environment:
      - OLLAMA_HOST=ollama:11434

  # Agent service: LangGraph orchestrator
  agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
    container_name: msia-agent
    env_file: .env
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import os; import redis; r=redis.Redis(host='redis', port=6379, password=os.environ.get('REDIS_PASSWORD')); r.ping()\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Admin Panel: NextJS + React modern admin interface
  admin-panel:
    build:
      context: .
      dockerfile: docker/Dockerfile.admin-panel
    container_name: msia-admin-panel
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_CHATWOOT_URL=${CHATWOOT_API_URL:-http://localhost:3000}
    ports:
      - "8001:3000"
    depends_on:
      api:
        condition: service_healthy
    networks:
      - msia-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "node -e \"fetch('http://localhost:3000').then(r => process.exit(r.ok ? 0 : 1)).catch(() => process.exit(1))\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 2G

  # Qdrant vector database for RAG
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: msia-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - msia-network
    restart: unless-stopped
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD-SHELL", "timeout 2 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Document Processor Worker for RAG
  document-processor:
    build:
      context: .
      dockerfile: docker/Dockerfile.worker
    container_name: msia-document-processor
    env_file: .env
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - msia-network
    restart: unless-stopped
    volumes:
      - ./uploads:/app/uploads
      - ocr_models:/usr/local/lib/python3.11/site-packages/rapidocr/models

networks:
  msia-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  ollama_data:
  qdrant_data:
  ocr_models:
