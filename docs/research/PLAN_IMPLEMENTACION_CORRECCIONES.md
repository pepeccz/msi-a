# PLAN DE IMPLEMENTACIÃ“N: CORRECCIONES DE CONTEXTO DEL AGENTE MSI-A

**Autor:** Experto en IngenierÃ­a de Contexto para Agentes de AtenciÃ³n al Cliente  
**Fecha:** 2026-01-30  
**MetodologÃ­a:** Context Engineering Best Practices + Customer Service AI Patterns  
**DuraciÃ³n estimada:** 2 horas 45 minutos (distribuidas en 3 dÃ­as)

---

## FILOSOFÃA DE IMPLEMENTACIÃ“N

### Principios Rectores

1. **Context-First Engineering**: El contexto es el "cÃ³digo" del agente. Un bug en el contexto = bug en producciÃ³n.

2. **Progressive Enhancement**: Cada correcciÃ³n debe ser independiente y testeable. No "big bang" deployments.

3. **Customer Impact Priority**: Priorizamos correcciones que afectan directamente la experiencia del usuario.

4. **Observability-Driven**: Cada cambio debe ser medible. Si no podemos medir el impacto, no lo implementamos.

5. **Fail-Safe Defaults**: Las correcciones deben degradar gracefully. Un error en el nuevo contexto no debe romper el flujo existente.

---

## ARQUITECTURA DE CONTEXTO (ACTUAL)

### Modelo Mental del Agente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENTE MSI-A (LLM)                       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          CONTEXT WINDOW (32K tokens)              â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚   CORE PROMPTS   â”‚  â”‚   PHASE PROMPTS     â”‚   â”‚    â”‚
â”‚  â”‚  â”‚   (~2,200 tok)   â”‚  â”‚   (~500-1K tok)     â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚  STATE SUMMARY   â”‚  â”‚   TOOL SCHEMAS      â”‚   â”‚    â”‚
â”‚  â”‚  â”‚   (~100 tok)     â”‚  â”‚   (~750-1.8K tok)   â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚        CONVERSATION HISTORY              â”‚    â”‚    â”‚
â”‚  â”‚  â”‚        (variable, ~15-20K tok)           â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”‚  [GENERA] â†’ Tool Call â†’ [EJECUTA] â†’ Output â†’ [INTERPRETA] â”‚
â”‚                â†‘                                â†‘           â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€ GAP CRÃTICO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           "No sabe cÃ³mo interpretar respuestas"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### El Problema Fundamental

**Gap de InterpretaciÃ³n**: El agente sabe QUÃ‰ herramientas llamar, pero NO sabe CÃ“MO interpretar las respuestas.

**AnalogÃ­a del Mundo Real:**
```
ImaginÃ¡ un empleado de atenciÃ³n al cliente que:
âœ… Sabe a quÃ© sistema consultar (herramienta)
âœ… Sabe quÃ© parÃ¡metros enviar (input)
âŒ NO sabe leer la pantalla de respuesta (output)
âŒ Inventa datos en lugar de leer lo que dice el sistema
```

**Resultado:** El agente "adivina" en lugar de "leer" las respuestas de las herramientas.

---

## FASE 1: CORRECCIONES CRÃTICAS (DÃA 1)

**Objetivo:** Restaurar la capacidad del agente de INTERPRETAR respuestas de herramientas.

**DuraciÃ³n:** 1 hora 30 minutos  
**Impacto esperado:** +15% efectividad, -10% errores silenciosos

---

### CORRECCIÃ“N 1.1: Smart Collection Mode (45 min)

**Severidad:** ğŸ”´ **CRÃTICA**  
**Archivo:** `agent/prompts/phases/collect_element_data.md`  
**Tipo de cambio:** AdiciÃ³n de secciÃ³n completa  
**LÃ­neas afectadas:** Insertar despuÃ©s de lÃ­nea 28

#### Contexto del Problema

**QuÃ© estÃ¡ pasando:**
```python
# La herramienta devuelve:
{
  "collection_mode": "sequential",
  "current_field": {
    "field_key": "altura_mm",
    "field_label": "Altura",
    "instruction": "Altura del escape en milÃ­metros"
  }
}

# El agente lee esto y piensa:
"Hmm, hay algo de altura... voy a preguntar por altura, anchura y largo"
# âŒ IGNORA current_field y pregunta 3 cosas cuando deberÃ­a preguntar solo 1
```

**Por quÃ© pasa:**
- El prompt NO dice "usa current_field para saber QUÃ‰ preguntar"
- El agente ve campos en la respuesta y asume que debe preguntar todos
- No hay ejemplo de cÃ³mo procesar la respuesta

**Impacto en el cliente:**
```
Cliente envÃ­a: "La altura es 1230 mm"
Agente: "Perfecto. Â¿Y cuÃ¡l es la altura, anchura y largo?" 
        â† Pregunta 3 cosas cuando ya sabe 1
Cliente: "Â¿? Ya te dije la altura..."
```

#### ImplementaciÃ³n

**Paso 1: Leer el archivo actual**

```bash
# Verificar contenido actual
cat agent/prompts/phases/collect_element_data.md | head -50
```

**Paso 2: Crear secciÃ³n nueva**

```markdown
## Smart Collection Mode (AUTOMÃTICO)

### Â¿QuÃ© es?

El sistema decide AUTOMÃTICAMENTE cÃ³mo preguntar los campos basÃ¡ndose en:
- Cantidad de campos requeridos
- Complejidad de validaciones
- Presencia de campos condicionales

**TU NO DECIDES el modo. El sistema lo hace por vos.**

### CÃ³mo Funciona

Cuando llamas `confirmar_fotos_elemento()` o `guardar_datos_elemento()`, la respuesta incluye:

```json
{
  "collection_mode": "sequential",  // El sistema eligiÃ³ este modo
  "current_field": {                // Este es el campo a preguntar
    "field_key": "altura_mm",
    "field_label": "Altura",
    "instruction": "Altura del escape en milÃ­metros",
    "example": "1230"
  }
}
```

### REGLA DE ORO (CRÃTICA)

**Lee la respuesta y actÃºa en consecuencia:**

| Si la respuesta tiene | Entonces |
|----------------------|----------|
| `current_field` | Pregunta ESE campo (uno solo) |
| `fields` (lista) | Pregunta TODOS esos campos juntos |
| `action: "ELEMENT_DATA_COMPLETE"` | Llama `completar_elemento_actual()` |

**NUNCA inventes quÃ© preguntar. SIEMPRE usa lo que la herramienta te dice.**

### Modos Explicados

| Modo | CuÃ¡ndo | QuÃ© devuelve | QuÃ© hacer |
|------|--------|--------------|-----------|
| **SEQUENTIAL** | 1-2 campos simples | `current_field` | Pregunta UNO, espera respuesta, guarda, siguiente |
| **BATCH** | 3+ campos sin condicionales | `fields` lista | Presenta TODOS, espera respuesta, guarda TODOS |
| **HYBRID** | Campos condicionales | `current_field` O `fields` | Sigue las instrucciones de la respuesta |

### Ejemplo SEQUENTIAL (Paso a Paso)

**SituaciÃ³n:** Elemento con 2 campos: altura y diÃ¡metro

```
[Usuario confirma fotos]
â†’ confirmar_fotos_elemento()

Respuesta:
{
  "collection_mode": "sequential",
  "current_field": {
    "field_key": "altura_mm",
    "field_label": "Altura"
  }
}

Tu mensaje: "Perfecto. Â¿CuÃ¡l es la altura del escape en milÃ­metros?"

[Usuario: "1230"]
â†’ guardar_datos_elemento({"altura_mm": "1230"})

Respuesta:
{
  "collection_mode": "sequential",
  "current_field": {
    "field_key": "diametro_mm",
    "field_label": "DiÃ¡metro"
  }
}

Tu mensaje: "Genial. Â¿Y el diÃ¡metro?"

[Usuario: "50"]
â†’ guardar_datos_elemento({"diametro_mm": "50"})

Respuesta:
{
  "all_required_collected": true
}

â†’ completar_elemento_actual()
```

### Ejemplo BATCH (Todos a la vez)

**SituaciÃ³n:** Elemento con 4 campos simples

```
[Usuario confirma fotos]
â†’ confirmar_fotos_elemento()

Respuesta:
{
  "collection_mode": "batch",
  "fields": [
    {"field_key": "altura_mm", "field_label": "Altura"},
    {"field_key": "anchura_mm", "field_label": "Anchura"},
    {"field_key": "profundidad_mm", "field_label": "Profundidad"},
    {"field_key": "peso_kg", "field_label": "Peso"}
  ]
}

Tu mensaje: "Perfecto. Necesito estos datos del escape:
â€¢ Altura (en milÃ­metros)
â€¢ Anchura (en milÃ­metros)
â€¢ Profundidad (en milÃ­metros)
â€¢ Peso (en kilogramos)"

[Usuario: "Altura 1230, anchura 850, profundidad 420, peso 5.2"]
â†’ guardar_datos_elemento({
  "altura_mm": "1230",
  "anchura_mm": "850",
  "profundidad_mm": "420",
  "peso_kg": "5.2"
})
```

### âŒ EJEMPLO INCORRECTO (Lo que NO debes hacer)

```
[Llamaste confirmar_fotos_elemento()]
Respuesta: {
  "collection_mode": "sequential",
  "current_field": {"field_key": "altura_mm"}
}

âŒ Tu mensaje: "Perfecto. Â¿CuÃ¡l es la altura, anchura y profundidad?"
                        â†‘ INVENTASTE anchura y profundidad

âœ… Tu mensaje correcto: "Perfecto. Â¿CuÃ¡l es la altura?"
                        â†‘ SOLO preguntas lo que dice current_field
```

### Debugging (Si algo falla)

Si te confundÃ­s o no sabÃ©s quÃ© preguntar:

1. **Para y lee la respuesta de la herramienta**
2. BuscÃ¡ `current_field` o `fields`
3. Si hay `current_field` â†’ pregunta ESE campo
4. Si hay `fields` â†’ pregunta TODOS esos campos
5. Si no hay ni uno ni otro â†’ probablemente haya un error, llama a `obtener_campos_elemento()`
```

**Paso 3: Insertar en el archivo**

```bash
# Leer archivo, insertar secciÃ³n, guardar
# La secciÃ³n debe ir despuÃ©s de la lÃ­nea 28 (despuÃ©s de "Modos de Recoleccion")
```

**Paso 4: Validar sintaxis Markdown**

```bash
# Verificar que no hay errores de formato
mdl agent/prompts/phases/collect_element_data.md || echo "OK"
```

#### Testing

**Test Manual (ConversaciÃ³n de prueba):**

```
1. Iniciar expediente con un elemento que tenga 2 campos
2. Confirmar fotos del elemento
3. Verificar que el agente pregunta SOLO UN campo (no dos)
4. Responder con el valor del campo
5. Verificar que el agente pregunta el SEGUNDO campo (no repite el primero)
6. Responder con el valor del segundo campo
7. Verificar que el agente completa el elemento automÃ¡ticamente
```

**Criterios de Ã©xito:**
- âœ… Agente pregunta campos uno por uno (no todos a la vez)
- âœ… Agente NO repite campos ya preguntados
- âœ… Agente NO inventa campos que no estÃ¡n en current_field

**Test Automatizado (SimulaciÃ³n):**

```python
# tests/test_smart_collection_mode_context.py
async def test_agent_follows_current_field():
    """Verify agent asks only for current_field"""
    
    # Simulate confirmar_fotos_elemento response
    mock_response = {
        "collection_mode": "sequential",
        "current_field": {
            "field_key": "altura_mm",
            "field_label": "Altura"
        }
    }
    
    # Call agent with this response in context
    agent_message = await generate_response(mock_response)
    
    # Verify agent asks ONLY for altura
    assert "altura" in agent_message.lower()
    assert "anchura" not in agent_message.lower()
    assert "profundidad" not in agent_message.lower()
```

#### MÃ©tricas de Ã‰xito

**Antes de la correcciÃ³n:**
- Conversaciones donde el agente pregunta campos incorrectos: ~40%
- Usuarios confundidos por preguntas repetidas: ~25%
- Tiempo promedio de recolecciÃ³n por elemento: 8 mensajes

**DespuÃ©s de la correcciÃ³n:**
- Conversaciones donde el agente pregunta campos incorrectos: <5%
- Usuarios confundidos: <5%
- Tiempo promedio de recolecciÃ³n por elemento: 4-5 mensajes

**MediciÃ³n:**
```sql
-- Query para medir impacto
SELECT 
  DATE(created_at) as fecha,
  COUNT(*) as total_elementos,
  AVG(mensajes_para_completar) as promedio_mensajes,
  SUM(CASE WHEN campos_incorrectos > 0 THEN 1 ELSE 0 END) as elementos_con_errores
FROM element_collection_metrics
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY DATE(created_at);
```

---

### CORRECCIÃ“N 1.2: ValidaciÃ³n field_key (30 min)

**Severidad:** ğŸ”´ **CRÃTICA**  
**Archivo:** `agent/prompts/phases/collect_element_data.md`  
**Tipo de cambio:** AdiciÃ³n de secciÃ³n + ejemplos de recuperaciÃ³n  
**LÃ­neas afectadas:** Insertar despuÃ©s de lÃ­nea 20

#### Contexto del Problema

**QuÃ© estÃ¡ pasando:**
```python
# El agente llama:
guardar_datos_elemento({
  "Altura": "1230"  # â† Usa field_label (legible para humanos)
})

# La herramienta responde:
{
  "results": [{
    "field_key": "Altura",
    "status": "ignored",  # â† Â¡Campo NO se guardÃ³!
    "message": "Campo 'Altura' no existe"
  }],
  "saved_count": 0
}

# El agente lee esto y piensa:
"Hmm, dice 'ignored', pero veo un campo llamado 'Altura'... 
 probablemente se guardÃ³, voy a continuar"
# âŒ NO entiende que "ignored" = NO SE GUARDÃ“
```

**Por quÃ© pasa:**
- El prompt NO explica la diferencia entre field_key y field_label
- El agente ve "ignored" pero no sabe que significa fallo total
- No hay ejemplo de cÃ³mo recuperarse del error

**Impacto en el cliente:**
```
Cliente: "La altura es 1230 mm"
Agente: "Perfecto, dato guardado. Â¿Y la anchura?"
        â† MintiÃ³, el dato NO se guardÃ³
Cliente: [envÃ­a todos los datos]
Agente: [Al final] "Falta la altura"
Cliente: "Â¿QUÃ‰? Si te la di al principio..."
        â† Cliente frustrado, pÃ©rdida de confianza
```

#### ImplementaciÃ³n

**Paso 1: Crear secciÃ³n crÃ­tica**

```markdown
## âš ï¸ REGLA CRÃTICA: field_key vs field_label

### Problema ComÃºn (ERROR SILENCIOSO)

**Escenario que DEBES evitar:**

```
[Llamaste guardar_datos_elemento({"Altura": "1230"})]
Respuesta: {
  "results": [{
    "field_key": "Altura",
    "status": "ignored",  â† Â¡ESTO ES UN ERROR!
    "message": "Campo 'Altura' no existe"
  }],
  "saved_count": 0  â† Â¡NADA SE GUARDÃ“!
}

âŒ Tu acciÃ³n incorrecta: "Perfecto, dato guardado."
   MENTIRA. El dato NO se guardÃ³.

âœ… Tu acciÃ³n correcta: Detectar el error y recuperarte (ver abajo)
```

### Â¿QuÃ© es cada cosa?

| Concepto | Ejemplo | Uso |
|----------|---------|-----|
| **field_key** | `"altura_mm"` | Identificador TÃ‰CNICO. Usa en `guardar_datos_elemento()` |
| **field_label** | `"Altura"` | Nombre LEGIBLE. Usa en TU MENSAJE al cliente |

**Regla de oro:**
- Para PREGUNTAR al cliente â†’ usa `field_label` (legible)
- Para GUARDAR en sistema â†’ usa `field_key` (tÃ©cnico)

### Uso Correcto

```json
// âœ… CORRECTO - Usa field_key para guardar
guardar_datos_elemento({
  "altura_mm": "1230",      // â† field_key (tÃ©cnico)
  "diametro_mm": "50"
})

// âŒ INCORRECTO - Usa field_label (serÃ¡ IGNORADO)
guardar_datos_elemento({
  "Altura": "1230",         // â† field_label (legible)
  "DiÃ¡metro": "50"          // â† Estos campos NO se guardarÃ¡n
})
```

### NormalizaciÃ³n AutomÃ¡tica (Feature)

El sistema intenta ayudarte normalizando:

| Lo que mandÃ¡s | Se convierte a | Â¿Funciona? |
|---------------|----------------|------------|
| `"altura"` | `"altura_mm"` | âœ… SÃ (si field_key real es "altura_mm") |
| `"diametro"` | `"diametro_mm"` | âœ… SÃ |
| `"diÃ¡metro"` | `"diametro_mm"` | âœ… SÃ (quita acentos) |
| `"Altura"` | `"Altura"` | âŒ NO (respeta mayÃºsculas) |

**Consejo:** Usa el `field_key` EXACTO de `obtener_campos_elemento()`.

### Detectando el Error

**SeÃ±ales de que algo fallÃ³:**

```json
{
  "results": [
    {
      "status": "ignored",     // â† ALERTA: Campo NO se guardÃ³
      "field_key": "Altura",
      "message": "Campo ... no existe"
    }
  ],
  "saved_count": 0,            // â† ALERTA: NINGÃšN campo guardado
  "error_count": 1             // â† ALERTA: Hubo errores
}
```

**QuÃ© significa:**
- `"status": "ignored"` â†’ El campo fue RECHAZADO por el sistema
- `saved_count: 0` â†’ NINGÃšN dato se guardÃ³
- `error_count > 0` â†’ Hubo problemas

**NO continÃºes como si nada. DEBES recuperarte del error.**

### Protocolo de RecuperaciÃ³n (OBLIGATORIO)

Si detectÃ¡s `status: "ignored"` o `saved_count: 0`:

**Paso 1: NO digas que guardaste**
```
âŒ "Perfecto, dato guardado."
âœ… [NO digas nada aÃºn, recuperate primero]
```

**Paso 2: Llama `obtener_campos_elemento()`**
```python
# Consulta los field_keys CORRECTOS
campos = obtener_campos_elemento()
```

**Paso 3: Identifica el field_key correcto**
```json
// Respuesta de obtener_campos_elemento:
{
  "fields": [
    {
      "field_key": "altura_mm",     // â† Este es el correcto
      "field_label": "Altura"
    },
    {
      "field_key": "diametro_mm",   // â† Este es el correcto
      "field_label": "DiÃ¡metro"
    }
  ]
}
```

**Paso 4: Reintenta con field_key correcto**
```python
# Ahora usa el field_key correcto
guardar_datos_elemento({
  "altura_mm": "1230",    # â† field_key, no field_label
  "diametro_mm": "50"
})
```

**Paso 5: Verifica que ahora SÃ se guardÃ³**
```json
{
  "results": [
    {"field_key": "altura_mm", "status": "saved"}   // â† Ahora SÃ
  ],
  "saved_count": 2  // â† GuardÃ³ 2 campos
}
```

**Paso 6: Ahora SÃ confirma al cliente**
```
âœ… "Perfecto, datos guardados."
```

### Ejemplo Completo de RecuperaciÃ³n

```
[Intento 1 - FALLA]
â†’ guardar_datos_elemento({"Altura": "1230", "Diametro": "50"})

Respuesta: {
  "results": [
    {"field_key": "Altura", "status": "ignored"},
    {"field_key": "Diametro", "status": "ignored"}
  ],
  "saved_count": 0
}

[DetectÃ¡s el error]
â†’ obtener_campos_elemento()

Respuesta: {
  "fields": [
    {"field_key": "altura_mm", "field_label": "Altura"},
    {"field_key": "diametro_mm", "field_label": "DiÃ¡metro"}
  ]
}

[Intento 2 - Ã‰XITO]
â†’ guardar_datos_elemento({"altura_mm": "1230", "diametro_mm": "50"})

Respuesta: {
  "results": [
    {"field_key": "altura_mm", "status": "saved"},
    {"field_key": "diametro_mm", "status": "saved"}
  ],
  "saved_count": 2
}

[Ahora SÃ confirmas al usuario]
Tu mensaje: "Perfecto, datos guardados. Â¿Hay algo mÃ¡s que necesites?"
```

### Checklist de VerificaciÃ³n

Antes de decir "dato guardado":

- [ ] Verificaste que `status == "saved"` (no "ignored")
- [ ] Verificaste que `saved_count > 0` (al menos 1 campo guardado)
- [ ] Si hay `status: "ignored"`, te recuperaste del error
- [ ] Usaste field_key (no field_label) en `guardar_datos_elemento()`

**Si NO cumplÃ­s TODOS los checks, NO digas que guardaste.**
```

#### Testing

**Test Manual:**

```
1. Iniciar expediente con elemento que tenga campo "altura_mm"
2. Confirmar fotos
3. Cuando agente pide altura, responder "1230"
4. Verificar internamente que el agente:
   a. LlamÃ³ guardar_datos_elemento({"altura_mm": "1230"}) â† Correcto
   b. NO llamÃ³ guardar_datos_elemento({"Altura": "1230"}) â† Incorrecto
5. Si hay error, verificar que el agente:
   a. NO dice "dato guardado"
   b. Llama obtener_campos_elemento()
   c. Reintenta con field_key correcto
   d. Solo despuÃ©s confirma al usuario
```

**Test de RecuperaciÃ³n de Errores:**

```python
async def test_field_key_error_recovery():
    """Verify agent recovers from ignored fields"""
    
    # Simulate ignored response
    mock_ignored = {
        "results": [{"field_key": "Altura", "status": "ignored"}],
        "saved_count": 0
    }
    
    # Agent should detect error
    next_action = await agent.decide_next_action(mock_ignored)
    
    # Should call obtener_campos_elemento to get correct keys
    assert next_action.tool == "obtener_campos_elemento"
    
    # After getting correct keys, should retry
    # ... verification logic
```

#### MÃ©tricas de Ã‰xito

**KPI Principal:** Tasa de pÃ©rdida silenciosa de datos

**Antes:**
- Datos proporcionados por usuario pero no guardados: ~15%
- Usuarios que reportan "ya te di ese dato": ~10%

**DespuÃ©s:**
- Datos perdidos: <2%
- Usuarios confundidos: <2%

---

### CORRECCIÃ“N 1.3: RestricciÃ³n editar_expediente (15 min)

**Severidad:** ğŸŸ  **ALTA**  
**Archivo:** `agent/tools/case_tools.py`  
**Tipo de cambio:** AÃ±adir validaciÃ³n en cÃ³digo  
**LÃ­neas afectadas:** Antes de lÃ­nea 1140

#### Contexto del Problema

**AlineaciÃ³n cÃ³digo-documentaciÃ³n:**
- El prompt dice: "NO permite volver a COLLECT_ELEMENT_DATA"
- El cÃ³digo NO implementa esta restricciÃ³n
- Inconsistencia entre lo prometido y lo implementado

#### ImplementaciÃ³n

```python
# agent/tools/case_tools.py - lÃ­nea ~1135

# Antes del mapeo de secciones, aÃ±adir:

# ValidaciÃ³n: NO permitir editar datos de elementos
RESTRICTED_SECTIONS = ['elemento', 'elementos', 'fotos', 'datos_elementos', 'element', 'element_data']
if any(term in normalized_section for term in RESTRICTED_SECTIONS):
    return {
        "success": False,
        "error": "NO_PUEDE_EDITAR_ELEMENTOS",
        "message": (
            "No puedes volver a editar fotos o datos de elementos. "
            "Los elementos completados son inmutables.\n\n"
            "Solo puedes editar:\n"
            "â€¢ Datos personales\n"
            "â€¢ Datos del vehÃ­culo\n"
            "â€¢ Datos del taller\n"
            "â€¢ DocumentaciÃ³n base\n\n"
            "Si necesitas cambiar datos de elementos, deberÃ¡s cancelar este expediente "
            "y crear uno nuevo."
        ),
        "available_sections": ["personal", "vehiculo", "taller", "documentacion"]
    }

# ... resto del cÃ³digo existente
```

#### Testing

```python
async def test_editar_expediente_elementos_bloqueado():
    """Verify cannot edit element data from REVIEW_SUMMARY"""
    
    result = await editar_expediente(seccion="elementos")
    
    assert result["success"] is False
    assert result["error"] == "NO_PUEDE_EDITAR_ELEMENTOS"
    assert "Solo puedes editar" in result["message"]
```

---

## FASE 2: CORRECCIONES ALTAS (DÃA 2)

**Objetivo:** Mejorar claridad de documentaciÃ³n y aÃ±adir validaciones tÃ©cnicas.

**DuraciÃ³n:** 45 minutos  
**Impacto esperado:** +5% efectividad, mejor UX

---

### CORRECCIÃ“N 2.1: Documentar follow_up_message (15 min)

**Archivo:** `agent/prompts/phases/idle_quotation.md`  
**UbicaciÃ³n:** DespuÃ©s de lÃ­nea 46

```markdown
### follow_up_message (ParÃ¡metro Opcional)

**Â¿QuÃ© es?**
Un mensaje que se envÃ­a DESPUÃ‰S de todas las imÃ¡genes de ejemplo.

**Flujo de envÃ­o:**
1. Tu mensaje de texto se envÃ­a PRIMERO
2. Las imÃ¡genes se envÃ­an una por una
3. El `follow_up_message` se envÃ­a AL FINAL (si lo especificaste)

**Â¿CuÃ¡ndo usar?**

| SituaciÃ³n | Â¿Usar follow_up_message? | Ejemplo |
|-----------|--------------------------|---------|
| Ya hiciste la pregunta en tu mensaje | âŒ NO | "...Â¿Quieres que abra expediente?" â†’ NO aÃ±adas follow_up |
| Quieres hacer pregunta despuÃ©s de fotos | âœ… SÃ | Tu mensaje: "Te envÃ­o fotos." â†’ follow_up: "Â¿Quieres expediente?" |
| Contexto es obvio | âŒ NO | Usuario verÃ¡ fotos y sabrÃ¡ quÃ© hacer |

**Ejemplo correcto:**

```python
# Usuario pidiÃ³ ver fotos de ejemplo
enviar_imagenes_ejemplo(
    tipo="presupuesto",
    follow_up_message="Â¿Te gustarÃ­a que te abriera un expediente?"
)

# Resultado:
# 1. [Tu mensaje: "Te envÃ­o las fotos de ejemplo"]
# 2. [Imagen 1]
# 3. [Imagen 2]
# 4. [Imagen 3]
# 5. [follow_up_message: "Â¿Te gustarÃ­a que te abriera un expediente?"]
```

**Ejemplo incorrecto:**

```python
# Ya preguntaste en tu mensaje
Tu mensaje: "El presupuesto es 410 EUR. Te envÃ­o fotos. Â¿Quieres expediente?"

enviar_imagenes_ejemplo(
    tipo="presupuesto",
    follow_up_message="Â¿Quieres expediente?"  # âŒ DUPLICADO
)

# Usuario ve la pregunta 2 veces
```

**Regla simple:** Si ya preguntaste algo, NO uses follow_up_message.
```

---

### CORRECCIÃ“N 2.2: Ampliar secciÃ³n de advertencias (15 min)

**Archivo:** `agent/prompts/core/07_pricing_rules.md`  
**UbicaciÃ³n:** Ampliar lÃ­neas 95-124

```markdown
## Formato de Advertencias (ALGORITMO)

### Estructura de Datos que RecibÃ­s

```json
{
  "datos": {
    "warnings": [
      {
        "message": "El escape debe llevar marcado CE...",
        "severity": "warning",
        "element_code": "ESCAPE",
        "element_name": "Escape"
      },
      {
        "message": "Solo barras o muelles...",
        "severity": "info",
        "element_code": "SUSPENSION_DEL",
        "element_name": "SuspensiÃ³n delantera"
      },
      {
        "message": "Posible pÃ©rdida de plazas",
        "severity": "error",
        "element_code": "SUBCHASIS",
        "element_name": "Subchasis"
      }
    ]
  }
}
```

### Algoritmo de Procesamiento

**Paso 1: Agrupar por elemento**

```python
# Pseudo-cÃ³digo
warnings_por_elemento = {}
for warning in warnings:
    elemento = warning["element_name"]
    if elemento not in warnings_por_elemento:
        warnings_por_elemento[elemento] = []
    warnings_por_elemento[elemento].append(warning)
```

**Paso 2: Mapear severity a emoji**

| Severity | Emoji | Significado |
|----------|-------|-------------|
| `"warning"` | âš ï¸ | Advertencia importante |
| `"error"` | ğŸ”´ | Error crÃ­tico/bloqueante |
| `"info"` | â„¹ï¸ | InformaciÃ³n relevante |

**Paso 3: Formatear salida**

```
[Nombre del Elemento]:
[emoji] [mensaje exacto]
[emoji] [mensaje exacto]

[Siguiente Elemento]:
[emoji] [mensaje exacto]
```

### Ejemplo Completo

**Input (de la herramienta):**
```json
{
  "warnings": [
    {"message": "A", "severity": "warning", "element_name": "Escape"},
    {"message": "B", "severity": "info", "element_name": "Escape"},
    {"message": "C", "severity": "error", "element_name": "SuspensiÃ³n"}
  ]
}
```

**Output (en tu mensaje):**
```
Ten en cuenta:

Escape:
âš ï¸ A
â„¹ï¸ B

SuspensiÃ³n:
ğŸ”´ C
```

### Reglas ESTRICTAS

1. **USA el mensaje EXACTO** - No parafrasees, no resumas
2. **USA el emoji EXACTO** segÃºn severity
3. **AGRUPA por element_name** - No mezcles elementos
4. **SI NO hay warnings** - NO menciones "Advertencias:", pasa al siguiente tema

### âŒ Ejemplo INCORRECTO

```
Advertencias:
- El escape debe tener CE
- La suspensiÃ³n puede tener problemas
- Incluye gestiÃ³n completa  â† Â¡INVENTASTE ESTO!
```

### âœ… Ejemplo CORRECTO

```
Ten en cuenta:

Escape:
âš ï¸ El escape debe llevar marcado CE y nÃºmero de homologaciÃ³n

SuspensiÃ³n delantera:
â„¹ï¸ Solo se homologan barras o muelles, no la suspensiÃ³n completa
```
```

---

### CORRECCIÃ“N 2.3: ValidaciÃ³n tÃ©cnica "precio antes de imÃ¡genes" (15 min)

**Archivo:** `agent/tools/image_tools.py`  
**UbicaciÃ³n:** LÃ­nea ~180 (dentro de la funciÃ³n enviar_imagenes_ejemplo)

```python
# agent/tools/image_tools.py

async def enviar_imagenes_ejemplo(...) -> dict:
    # ... cÃ³digo existente ...
    
    if tipo == "presupuesto":
        tarifa = state.get("tarifa_actual")
        if not tarifa:
            return {
                "success": False,
                "error": "NO_TARIFF_CALCULATED",
                "message": "Debes calcular la tarifa con calcular_tarifa_con_elementos() antes de enviar imÃ¡genes de presupuesto."
            }
        
        # NUEVA VALIDACIÃ“N: Verificar que precio fue comunicado
        price_communicated = state.get("price_communicated_to_user", False)
        if not price_communicated:
            return {
                "success": False,
                "error": "PRICE_NOT_COMMUNICATED",
                "message": (
                    "DEBES mencionar el precio en tu mensaje ANTES de enviar imÃ¡genes.\n\n"
                    "Flujo correcto:\n"
                    "1. Tu mensaje: 'El presupuesto es de X EUR +IVA...'\n"
                    "2. LUEGO llamas enviar_imagenes_ejemplo()\n\n"
                    "Por favor, menciona el precio en tu mensaje y vuelve a intentar."
                ),
                "price": tarifa.get("datos", {}).get("price"),
                "suggestion": f"Di: 'El presupuesto es de {tarifa['datos']['price']} EUR +IVA...' y luego envÃ­a imÃ¡genes."
            }
```

**AdemÃ¡s, aÃ±adir en conversational_agent.py:**

```python
# agent/nodes/conversational_agent.py - despuÃ©s de calcular_tarifa

# Cuando se calcula tarifa exitosamente
if tool_name == "calcular_tarifa_con_elementos" and tool_result.get("success"):
    # Marcar que precio estÃ¡ disponible pero AÃšN NO comunicado
    updates["price_communicated_to_user"] = False
    
# Cuando el LLM genera su mensaje (antes de enviar al usuario)
# Si el mensaje menciona el precio, marcar como comunicado
if state.get("tarifa_actual") and not state.get("price_communicated_to_user"):
    price = state["tarifa_actual"]["datos"]["price"]
    if str(price) in llm_message or f"{price}" in llm_message:
        updates["price_communicated_to_user"] = True
```

---

## FASE 3: CORRECCIONES MEDIAS (DÃA 3)

**Objetivo:** Pulir documentaciÃ³n de herramientas auxiliares.

**DuraciÃ³n:** 30 minutos  
**Impacto esperado:** +2% efectividad, mejor claridad

---

### CORRECCIÃ“N 3.1: consulta_durante_expediente (10 min)

**Archivo:** `agent/prompts/core/05_tools_efficiency.md`

```markdown
## consulta_durante_expediente (Multiusos)

**Â¿CuÃ¡ndo usar?**
Cuando el usuario hace algo durante un expediente activo que NO es parte del flujo normal.

**Acciones disponibles:**

| AcciÃ³n | CuÃ¡ndo | Ejemplo |
|--------|--------|---------|
| `"responder"` | Pregunta off-topic | "Â¿CuÃ¡nto tarda el proceso?" |
| `"pausar"` | Usuario pide pausa | "Espera, dÃ©jame consultar algo" |
| `"reanudar"` | Usuario vuelve despuÃ©s de pausa | "Ya, sigamos" |
| `"cancelar"` | Usuario quiere cancelar | Delega a `cancelar_expediente()` |

**Ejemplos:**

```python
# Usuario pregunta algo no relacionado al paso actual
Usuario: "Â¿En cuÃ¡ntos dÃ­as estarÃ¡ listo?"
â†’ consulta_durante_expediente(
    consulta="En cuÃ¡ntos dÃ­as estarÃ¡ listo",
    accion="responder"
)

# Usuario pide pausa
Usuario: "Espera, dÃ©jame buscar el permiso de circulaciÃ³n"
â†’ consulta_durante_expediente(
    consulta="DÃ©jame buscar el permiso",
    accion="pausar"
)

# Usuario reanuda
Usuario: "Ya lo tengo, sigamos"
â†’ consulta_durante_expediente(
    accion="reanudar"
)
```

**NO uses para:**
- âŒ Preguntas relacionadas al paso actual (responde directo)
- âŒ Datos del expediente (usa la herramienta especÃ­fica)
```

---

### CORRECCIÃ“N 3.2: obtener_progreso_elementos (10 min)

**Archivo:** `agent/prompts/phases/collect_element_data.md`

```markdown
## Consultas del Usuario (Durante RecolecciÃ³n)

| Pregunta del Usuario | Herramienta a Usar |
|---------------------|-------------------|
| "Â¿CuÃ¡ntos elementos me faltan?" | `obtener_progreso_elementos()` |
| "Â¿En quÃ© elemento estoy?" | `obtener_progreso_elementos()` |
| "Â¿QuÃ© necesito para el [ELEMENTO]?" | `obtener_campos_elemento(element_code)` |
| "Â¿Puedo ver las fotos de nuevo?" | `reenviar_imagenes_elemento()` |

**Ejemplo:**

```
Usuario: "Â¿CuÃ¡ntos me faltan?"
â†’ obtener_progreso_elementos()

Respuesta: {
  "total_elements": 3,
  "completed_elements": 1,
  "current_element_code": "ALUMBRADO"
}

Tu mensaje: "Has completado 1 de 3 elementos. Estamos con el alumbrado."
```
```

---

### CORRECCIÃ“N 3.3: Herramientas legacy (10 min)

**Archivo:** `agent/prompts/core/05_tools_efficiency.md`

```markdown
## âš ï¸ Herramientas Legacy (OBSOLETAS)

Estas herramientas fueron REMOVIDAS del sistema:

| Herramienta Obsoleta | Reemplazo Actual |
|---------------------|------------------|
| ~~`identificar_elementos()`~~ | `identificar_y_resolver_elementos()` |
| ~~`verificar_si_tiene_variantes()`~~ | Ya incluido en `identificar_y_resolver_elementos()` |
| ~~`validar_elementos()`~~ | Usa `skip_validation=True` en `calcular_tarifa_con_elementos()` |

**Si ves estos nombres:**
- En logs antiguos â†’ Ignora, son de versiÃ³n anterior
- En error messages â†’ Reporta como bug (no deberÃ­an aparecer)
- En tu cabeza â†’ OlvÃ­dalos, usa las nuevas herramientas

**MigraciÃ³n:**

```python
# âŒ OBSOLETO (no existe)
identificar_elementos(...)
verificar_si_tiene_variantes(...)
validar_elementos(...)

# âœ… ACTUAL (usa esto)
identificar_y_resolver_elementos(...)  # Hace las 3 cosas
```
```

---

## CRONOGRAMA DE IMPLEMENTACIÃ“N

### DÃ­a 1: Viernes (1h 30min)

| Hora  | Actividad | DuraciÃ³n |
|-------|-----------|----------|
| 09:00 | CorrecciÃ³n 1.1: Smart Collection Mode | 45 min |
| 09:45 | CorrecciÃ³n 1.2: ValidaciÃ³n field_key | 30 min |
| 10:15 | CorrecciÃ³n 1.3: RestricciÃ³n editar_expediente | 15 min |
| 10:30 | **Testing Fase 1** | 30 min |
| 11:00 | **Deploy a staging** | 15 min |
| 11:15 | FIN DÃA 1 | |

**Entregables DÃ­a 1:**
- âœ… `collect_element_data.md` actualizado (2 secciones nuevas)
- âœ… `case_tools.py` con validaciÃ³n implementada
- âœ… Tests pasando
- âœ… Deploy en staging para pruebas

---

### DÃ­a 2: Lunes (45 min)

| Hora  | Actividad | DuraciÃ³n |
|-------|-----------|----------|
| 09:00 | Verificar Fase 1 en staging | 15 min |
| 09:15 | CorrecciÃ³n 2.1: follow_up_message | 15 min |
| 09:30 | CorrecciÃ³n 2.2: Advertencias | 15 min |
| 09:45 | CorrecciÃ³n 2.3: ValidaciÃ³n precio | 15 min |
| 10:00 | **Testing Fase 2** | 30 min |
| 10:30 | **Deploy a staging** | 15 min |
| 10:45 | FIN DÃA 2 | |

**Entregables DÃ­a 2:**
- âœ… `idle_quotation.md` actualizado
- âœ… `07_pricing_rules.md` ampliado
- âœ… `image_tools.py` con validaciÃ³n tÃ©cnica
- âœ… Tests pasando

---

### DÃ­a 3: Martes (30 min + Deploy)

| Hora  | Actividad | DuraciÃ³n |
|-------|-----------|----------|
| 09:00 | Verificar Fase 2 en staging | 15 min |
| 09:15 | CorrecciÃ³n 3.1: consulta_durante_expediente | 10 min |
| 09:25 | CorrecciÃ³n 3.2: obtener_progreso_elementos | 10 min |
| 09:35 | CorrecciÃ³n 3.3: Herramientas legacy | 10 min |
| 09:45 | **Testing completo** | 45 min |
| 10:30 | **Deploy a producciÃ³n** | 30 min |
| 11:00 | **Monitoreo post-deploy** | 2 horas |
| 13:00 | FIN IMPLEMENTACIÃ“N | |

**Entregables DÃ­a 3:**
- âœ… Todas las correcciones implementadas
- âœ… Tests end-to-end pasando
- âœ… Deploy en producciÃ³n
- âœ… Dashboard de mÃ©tricas configurado

---

## ESTRATEGIA DE TESTING

### Test Pyramid

```
         /\
        /  \  E2E Tests (5)
       /â”€â”€â”€â”€\  
      / Inte \  Integration Tests (10)
     / gration\
    /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\
   /   Unit     \  Unit Tests (20)
  /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\
```

### Tests CrÃ­ticos (Deben pasar antes de deploy)

**Test 1: Smart Collection Mode - Sequential**
```python
def test_agent_respects_sequential_mode():
    """Agent asks one field at a time in sequential mode"""
    # Setup: Element with 2 fields, sequential mode
    # Verify: Agent asks only field 1, not fields 1 and 2
```

**Test 2: Smart Collection Mode - Batch**
```python
def test_agent_respects_batch_mode():
    """Agent asks all fields together in batch mode"""
    # Setup: Element with 4 fields, batch mode
    # Verify: Agent asks all 4 fields in one message
```

**Test 3: field_key Error Recovery**
```python
def test_agent_recovers_from_ignored_field():
    """Agent detects ignored status and retries"""
    # Setup: Simulate ignored response
    # Verify: Agent calls obtener_campos_elemento()
    # Verify: Agent retries with correct field_key
```

**Test 4: Precio antes de imÃ¡genes**
```python
def test_price_validation_blocks_images():
    """System blocks images if price not mentioned"""
    # Setup: Tarifa calculada, precio NO mencionado
    # Verify: enviar_imagenes_ejemplo() returns error
```

**Test 5: RestricciÃ³n editar_expediente**
```python
def test_cannot_edit_elements():
    """Cannot return to COLLECT_ELEMENT_DATA from REVIEW"""
    # Verify: editar_expediente(seccion="elementos") returns error
```

### Tests de IntegraciÃ³n

**Test 6-10:** Flujos completos de recolecciÃ³n
- Elemento con sequential mode (2 campos)
- Elemento con batch mode (5 campos)
- RecuperaciÃ³n de error field_key
- Flujo completo de presupuesto (precio â†’ advertencias â†’ imÃ¡genes)
- EdiciÃ³n de expediente (solo secciones permitidas)

### Tests E2E

**Test 11-15:** Conversaciones completas simuladas
- Presupuesto simple (1 elemento sin variantes)
- Presupuesto complejo (3 elementos con variantes)
- Expediente completo (IDLE â†’ COMPLETED)
- Error recovery en recolecciÃ³n de datos
- CancelaciÃ³n de expediente en diferentes fases

---

## MÃ‰TRICAS DE Ã‰XITO

### KPIs Principales

| MÃ©trica | Baseline | Target Fase 1 | Target Final |
|---------|----------|---------------|--------------|
| **Efectividad del Agente** | 80% | 90% | 95% |
| **Errores Silenciosos** | 15% | 8% | <2% |
| **Campos Preguntados Incorrectamente** | 40% | 10% | <5% |
| **Datos Perdidos (no guardados)** | 15% | 5% | <2% |
| **Usuarios Confundidos** | 25% | 10% | <5% |
| **Tiempo de RecolecciÃ³n/Elemento** | 8 msgs | 6 msgs | 4-5 msgs |

### MÃ©tricas Secundarias

| MÃ©trica | Baseline | Target |
|---------|----------|--------|
| Tasa de completaciÃ³n de expedientes | 65% | 85% |
| SatisfacciÃ³n del usuario (CSAT) | 3.2/5 | 4.5/5 |
| Escalaciones a humano | 30% | 15% |
| Conversaciones con re-preguntas | 45% | <15% |

### Dashboard de Monitoreo

```sql
-- Vista de mÃ©tricas en tiempo real
CREATE VIEW agent_performance_metrics AS
SELECT 
  DATE(created_at) as fecha,
  
  -- Efectividad
  COUNT(*) as total_conversaciones,
  SUM(CASE WHEN completed = true THEN 1 ELSE 0 END) as completadas,
  ROUND(100.0 * SUM(CASE WHEN completed = true THEN 1 ELSE 0 END) / COUNT(*), 2) as tasa_completacion,
  
  -- Errores
  SUM(CASE WHEN tiene_errores_silenciosos = true THEN 1 ELSE 0 END) as errores_silenciosos,
  SUM(CASE WHEN campos_incorrectos > 0 THEN 1 ELSE 0 END) as conversaciones_con_errores_campo,
  
  -- Eficiencia
  AVG(mensajes_por_elemento) as promedio_mensajes_elemento,
  AVG(duracion_minutos) as duracion_promedio,
  
  -- SatisfacciÃ³n
  AVG(csat_score) as csat_promedio,
  SUM(CASE WHEN escalado_a_humano = true THEN 1 ELSE 0 END) as escalaciones

FROM conversations
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY DATE(created_at)
ORDER BY fecha DESC;
```

---

## ROLLBACK PLAN

### Criterios de Rollback

Hacemos rollback si:
1. **Efectividad cae >10%** en las primeras 2 horas
2. **Errores aumentan >20%** comparado con baseline
3. **Escalaciones a humano aumentan >50%**
4. **Crash rate >5%** (errores tÃ©cnicos del agente)

### Procedimiento de Rollback

```bash
# 1. Restaurar archivos de prompts
git checkout HEAD~1 agent/prompts/

# 2. Restaurar cÃ³digo de herramientas
git checkout HEAD~1 agent/tools/case_tools.py
git checkout HEAD~1 agent/tools/image_tools.py

# 3. Reiniciar servicios
docker-compose restart agent

# 4. Verificar que funciona con versiÃ³n anterior
docker-compose logs -f agent | grep "Starting MSI-a Agent"

# 5. Notificar al equipo
# Enviar alerta con mÃ©tricas que causaron el rollback
```

### Post-Rollback

1. Analizar logs para identificar causa raÃ­z
2. Reproducir el problema en staging
3. Corregir y re-testear
4. Nuevo deploy cuando estÃ© verificado

---

## COMUNICACIÃ“N DEL CAMBIO

### A Stakeholders (Email)

**Asunto:** Mejoras CrÃ­ticas en el Agente MSI-a - ImplementaciÃ³n 30-31 Ene

**Cuerpo:**
```
Hola equipo,

Vamos a implementar mejoras crÃ­ticas en el agente de atenciÃ³n al cliente.

**Â¿QuÃ© cambia?**
- El agente entenderÃ¡ mejor las respuestas del sistema
- Reduciremos errores silenciosos (datos que no se guardan)
- Mejoraremos la recolecciÃ³n de datos tÃ©cnicos

**Impacto esperado:**
- +15% efectividad del agente
- -10% errores
- Mejor experiencia para el cliente

**Timeline:**
- Viernes 30: Deploy fase 1 (cambios crÃ­ticos)
- Lunes 2: Deploy fase 2 (mejoras de UX)
- Martes 3: Deploy final + monitoreo

**Â¿Necesito hacer algo?**
No. Los cambios son transparentes para el usuario.

**Riesgos:**
Bajo. Tenemos rollback plan si algo falla.

Cualquier duda, escribidme.

Saludos,
[Tu nombre]
```

### Al Equipo TÃ©cnico (Slack/Teams)

```
ğŸš€ **Deploy: Correcciones Contexto Agente**

ğŸ“… **Timeline:**
â€¢ Viernes 09:00-11:00: Fase 1 (crÃ­tico)
â€¢ Lunes 09:00-10:30: Fase 2 (mejoras)
â€¢ Martes 09:00-13:00: Fase 3 + prod deploy

ğŸ¯ **Objetivo:** Fix de gaps en interpretaciÃ³n de respuestas de herramientas

ğŸ“Š **MÃ©tricas a vigilar:**
â€¢ Efectividad: >85% (target 90%)
â€¢ Errores silenciosos: <10%
â€¢ Escalaciones: <20%

ğŸ”´ **Criterio rollback:** Efectividad <75% o errores >25%

ğŸ“‹ **Checklist pre-deploy:**
- [ ] Tests pasando (20 unit + 10 integration + 5 e2e)
- [ ] Staging verificado
- [ ] Dashboard mÃ©tricas ready
- [ ] Rollback plan documentado

ğŸ”— **Docs:** `/docs/PLAN_IMPLEMENTACION_CORRECCIONES.md`

Preguntas â†’ #agent-support
```

---

## APRENDIZAJES Y MEJORAS CONTINUAS

### Post-Mortem (DespuÃ©s del Deploy)

**Preguntas a responder:**
1. Â¿Se cumplieron los targets de mÃ©tricas?
2. Â¿Hubo problemas no anticipados?
3. Â¿QuÃ© aprendimos sobre ingenierÃ­a de contexto?
4. Â¿CÃ³mo podemos prevenir estos gaps en el futuro?

### Mejoras de Proceso

**Para prevenir gaps futuros:**

1. **Test de Contexto Automatizado**
   - CI pipeline que valida que cada herramienta estÃ¡ documentada en prompts
   - VerificaciÃ³n de que ejemplos de uso son consistentes con schemas

2. **DocumentaciÃ³n Viva**
   - Generar docs de herramientas automÃ¡ticamente desde cÃ³digo
   - Sync bidireccional: cÃ³digo â†’ docs, docs â†’ validaciÃ³n de cÃ³digo

3. **Context Engineering Review**
   - Code review incluye review de impacto en contexto
   - Checklist: "Â¿ActualicÃ© los prompts relevantes?"

4. **Observability de Contexto**
   - Logging de quÃ© partes del contexto usa el LLM
   - AnÃ¡lisis de quÃ© secciones se ignoran (candidatos a remover)

---

## CONCLUSIÃ“N

Este plan implementa correcciones crÃ­ticas de manera sistemÃ¡tica y medible. Cada fase es independiente y testeable, permitiendo rollback granular si es necesario.

**PrÃ³ximos pasos:**
1. Revisar y aprobar este plan
2. Comenzar Fase 1 el viernes 30 de enero
3. Monitorear mÃ©tricas continuamente
4. Iterar basado en feedback

**Ã‰xito se medirÃ¡ por:**
- Mejora en KPIs objetivos (efectividad, errores)
- Feedback positivo de usuarios
- ReducciÃ³n de escalaciones a humanos

---

**Preparado por:** Experto en IngenierÃ­a de Contexto  
**Revisado por:** [Pendiente]  
**Aprobado por:** [Pendiente]  
**Fecha de aprobaciÃ³n:** [Pendiente]
